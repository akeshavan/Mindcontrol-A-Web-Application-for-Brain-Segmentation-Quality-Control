\section{Discussion}

Mindcontrol is a configurable neuroinformatics dashboard that links study information and descriptive statistics with scientific data visualization, MR images, and their overlays (segmentation or otherwise). The three configurations demonstrated in this report show the link between MRI quality metrics and raw data, the link between Freesurfer regional volumes and segmentation quality, and the link between ANTS cortical thickness summary statistics and segmentation/thickness estimates of the volume. The platform is configurable, open-source, and software/pipeline agnostic, enabling researchers to configure it to their particular analyses. The dashboard allows researchers to assign editing tasks to others, who can then perform edits on the application itself. 

The Mindcontrol platform streamlines and standardizes Quality Control procedures. The traditional method of collaborative QC within a lab assembles disparate software components into a procedure that is vulnerable to clerical errors. The QC operators use existing viewers (such as FSLview or Freeview) to view and edit the images, making notes on a collaborative spreadsheet application (such as google-docs). They must carefully adhere to a common folder structure and naming convention so that other lab members and any automated processing scripts can locate these images. Distributions of scalar metrics are then plotted to identify outliers using a separate data analysis software program. The results of that analysis must then be reviewed using the imaging software to ensure that outliers are appropriately screened. This method is inherently inefficient because images must be loaded multiple times and attention split between the imaging platform and annotation software. Additionally, results of the QC must be maintained consistently across several software packages. Clerical errors are common and time-consuming to resolve because naming convention is not explicitly enforced, and manual edits could be lost within the filesystem without thorough documentation by research assistants. Google-spreadsheets are collaborative, but ideally this pass/fail/edited QC information would be directly linked to the data. Mindcontrol stores all notes, annotations, and QC results, and in-browser edits internally (Mongo database backend). User edits can be extracted automatically and written to the filesystem, eliminating the potential for clerical errors. Scalar metrics are linked to 3D images, enabling a user to inspect an outlier image with the click of a button. Mind-control is web-based, so it can be used on any device; QC operators can even use a tablet with stylus to edit, which is more natural than using a mouse.

There have been considerable efforts in this field to ensure data quality on a large scale. The human connectome project's extensive informatics pipeline, which includes a database service, QC procedures, and a data visualization platform, has been key to the project's success in collecting a large, high-quality dataset \cite{Marcus_2013}. The Allen Brain Atlas offers a comprehensive genetic, neuroanatomical, and connectivity web-based data exploration portal, linking an MRI viewer to data tables \cite{Sunkin_2012}. The open-source LORIS web-based data management system integrates an image viewer with extensive QC modules \cite{Das_2012}. Mindcontrol supplements these efforts by providing a lightweight and extensible data management and visualization system with the added capability to perform edits and curate annotations within the application. 

Table \ref{tab:examples} shows examples of subjects from the FCP, CoRR and ABIDE datasets with low-quality scans or segmentations, identified using Mindcontrol. The tails of various PCP-QAP metric distributions for both the ABIDE and CoRR datasets could be filtered interactively to isolate images with motion artifacts, extensive blurring, and noise. In the ABIDE dataset, filtering by the entropy focus criterion (EFC) greater than 17 identified images with extreme motion artifacts. The range of the EFC for the CoRR dataset was much smaller (less than 2) and the image with the highest EFC had no motion artifacts, but failed QC due to excessive defacing. In the ABIDE dataset, filtering for the high FWHM extremes identified images with motion artifacts, grainy/noisy images, and one extremely blurry image. On the other hand, in the CoRR dataset, the image with high FWHM had an extreme bias field. In the CoRR dataset, the images with very low contrast-to-noise (CNR) had motion artifacts, while the ABIDE images did not. Overall, examining the extremes of the PCP-QAP metrics with Mindcontrol identified outliers, but the relationship between artifacts and metrics varied by study.

Exploring the link between ANTS Cortical Thickness and the PCP-QAP metrics in the ABIDE dataset, we found that selecting the higher tail of average left- and right-postcentral gyrus thickness corresponded to datasets at the higher range of PCP-QAP FWHM. Conversely, selecting the lower tail of the precentral and postcentral gyrus thicknesses related to the lower range of the FWHM. It was difficult to pinpoint errors in the ANTS Cortical Thickness segmentation images because the data was normalized to MNI space. In the future, it would be better to QC each step of the ANTS pipeline to ensure that 1) segmentation in native space was accurate and 2) normalization to MNI space was reasonable.

Mindcontrol is particularly useful to investigate where errors occurred in segmentation algorithms. In the FCP dataset, the most common errors in segmentation with Freesurfer were that 1) parts of the temporal lobes were excluded from the segmentation and 2) the gray matter segmentation entered the dura. Scans with low-quality temporal lobe segmentation were found by selecting the lower tail of the amygdala or temporal pole volume distributions. Often, these images exhibited poor gray/white contrast in the temporal pole region, and low signal to noise. Initially, we observed that dura missclassification occurred most frequently in the precentral and postcentral gyri. We then selected data points with high precentral/postcentral volumes to locate these errors. However, scans in the middle of these metric distributions also exhibited dura misclassification, suggesting that this particular problem may be consistent across the entire dataset. In this example, it is necessary to QC every scan, regardless of where its summary metrics lie on the distribution.  

In cases where every scan must be quality controlled, Mindcontrol's summary statistic distributions and annotation features can help prioritize which images to edit first. It may be more likely that images at the tail ends of their distributions require more time to quality control, or be more challenging and require an editor with more experience. When training new editors, Mindcontrol's annotation and notes features allow users to ask questions, mark questionable part of the image with the point or curve annotation feature, and assign images to more senior editors to review and give feedback. When multiple users are editing images using traditional, non-browser based tools, it is up to the user to save their edited images in a consistent manner, so that new users know which images have been edited, and where the original image came from. Inconsistent naming and folder structures could cause confusion to other lab members, edits could be lost in the filesystem once the original editor leaves, or even accidentally over-written. Using Mindcontrol can help avoid this problem, because edits are curated within the Mindcontrol database. Mindcontrol saves the voxel coordinates and the new value of the voxel, but does not apply edits to the actual image. Users can write scripts to apply the Mindcontrol painter coordinates to a volume, and write the output in a consistent naming structure. An example python script to do this can be found at \href{http://}{https://github.com/akeshavan/mindcontrol/wiki/Applying-Painter-Edits}. Leveraging Mindcontrol as an integrated quality control tool can make processing methods more efficient, organized, and collaborative.


%Mindcontrol is actively being used at UCSF to study imaging biomarkers of multiple sclerosis (MS) disease progression in a 12-year longitudinal cohort of over 500 patients. MRI plays a crucial role in the diagnosis of MS due to its sensitivity to the white matter lesions characteristic of this disease \cite{ge2006multiple}. Both the location and number of lesions are used in the diagnostic criteria of MS \cite{mcdonald2001recommended}; their evolution over time is considered a proxy for disease progression, and is closely monitored as a key outcome measure in clinical trials \cite{ge2000glatiramer}. Researchers have identified numerous imaging biomarkers of disease progression, including cortical atrophy \cite{fisher2008gray} and sensitive lesion quantification methods from FLAIR sequences \cite{Schmidt_2012}. 

%Currently, Mindcontrol is being used as a data management dashboard and plays a role in the semi-automated identification of multiple sclerosis lesions. The Lesion Segmentation Toolbox (LST) automates the detection of FLAIR hyper-intense lesions, which prevents user-bias of the lesion boundary \cite{Schmidt_2012}. However, because our acquisition protocols sufficiently differ from those of the LST developers, manual intervention by neuroradiologists is often necessary to correct false positives and false negatives in our dataset. Mindcontrol's point annotation feature is used by neuroradiologists to mark the center of a false positive lesion. The curve annotation feature is used to quickly note the rough outline of a false negative lesion. Custom Python scripts use these annotations to produce a corrected lesion segmentation map, which is then used to tune the parameters of the LST. This method avoids biasing the lesion boundary and saves time by allowing users to quickly mark lesions with one click instead of the traditional method of coloring the full lesion volume by hand. Distributions of the lesion count and lesion volume are used by the researchers to prioritize the cases requiring more intensive editing.

%Mindcontrol is also being used at UCSF to coordinate a large-scale brain mask editing effort of $>$4000 exams in a cohort of multiple sclerosis patients. Using Mindcontrol's voxel editing or ``painting'' feature on a Microsoft Surface Pro 4 tablet with stylus, multiple research assistants are collaboratively erasing voxels incorrectly marked as brain and painting brain voxels that were not identified.  These edits are done with a stylus, which feels more natural and is faster than using a mouse. Researchers assign more complicated edits to the experts in the lab, write questions and comments in the ``notes'' section, and mark the brain as ``Edited'' once it is complete. A nightly cron-job applies their edits to the brain masks and assigns a reviewer to perform a final QC. All brains marked with a ``Pass'' will be added to a set of brain masks to be incorporated into a training set for the mincbeast brain extraction algorithm \cite{eskildsen2012beast}. 

