\section{Discussion}

Mindcontrol is a configurable neuroinformatics dashboard that links study information and descriptive statistics with scientific data visualization, MR images, and their overlays (segmentation or otherwise). The three configurations demonstrated in this report show the link between MRI quality metrics and raw data, the link between Freesurfer regional volumes and segmentation quality, and the link between ANTS cortical thickness summary statistics and segmentation/thickness estimates of the volume. The platform is configurable, open-source, and software/pipeline agnostic, enabling researchers to configure it to their particular analyses. The dashboard allows researchers to assign editing tasks to others, who can then perform edits on the application itself. 

There have been considerable efforts in this field to ensure data quality on a large scale. The human connectome project's extensive informatics pipeline, which includes a database service, QC procedures, and a data visualization platform, has been key to the project's success in collecting a large, high-quality dataset \cite{Marcus_2013}. The Allen Brain Atlas offers a comprehensive genetic, neuroanatomical, and connectivity web-based data exploration portal, linking an MRI viewer to data tables \cite{Sunkin_2012}. The open-source LORIS web-based data management system integrates an image viewer with extensive QC modules \cite{Das_2012}. Mindcontrol supplements these efforts by providing a lightweight and extensible data management and visualization system with the added capability to perform edits and curate annotations within the application. 

Table \ref{tab:examples} shows example subjects from the FCP, CoRR and ABIDE datasets with bad quality scans or segmentations. Filtering the edge of the distributions of various PCP-QAP metrics for both the ABIDE and CoRR datasets found various images with motion artifacts, extensive blurring and noise. In the ABIDE dataset, filtering the high end of the entropy focus criterion (EFC) greater than 17 found many images with extreme motion artifacts. The range of the EFC for the CoRR dataset was much smaller (less than 2) and the image with the highest EFC had no motion artifacts. However, the frontal lobe was cut off, probably due to excessive defacing. In the ABIDE dataset, filtering for the high FWHM extremes found images with motion artifacts, grainy/noisy images, and an extremely blurry image. On the other hand, in the CoRR dataset, the image with high FWHM had an extreme bias field. In the CoRR dataset, the images with very low contrast-to-noise (CNR) had motion artifacts, while the ABIDE images did not. Overall, examining the extremes of the FCP-QAP metrics with Mindcontrol found image artifacts, but the types of artifacts differed between the ABIDE and CoRR datasets. 

The link between ANTS Cortical Thickness and the PCP-QAP metrics in the ABIDE dataset was examined. We found that selecting the higher tail of average left- and right-postcentral gyrus thickness corresponded to datasets at the higher range of PCP-QAP FWHM. Conversely, selecting the lower tail of the precentral and postcentral gyrus thicknesses related to the lower range of the FWHM. It was difficult to pinpoint errors in the ANTS Cortical Thickness segmentation images because the data was normalized to MNI space. In the future, it would be better to QC each step of the ANTS pipeline, to ensure that 1) segmentation in native space was accurate and 2) that normalization to MNI space was reasonable. 

Mindcontrol is particularly useful to investigate where segmentation errors occurred for segmentation algorithms. In the FCP dataset, the most common errors in segmentation with Freesurfer were that 1) the temporal lobes were not fully segmented and 2) the gray matter segmentation enters the dura. Scans with bad-quality temporal lobe segmentation were found by selecting the lower tail of the amygdala or temporal pole volume distributions. Often, these images had poor gray/white contrast in the temporal pole region, and low signal to noise. Initially, we observed that dura missclassification occurred most frequently in the precentral and postcentral gyrus. We then selected images with high precentral/postcentral volumes to locate these images. However, there was still an issue for scans in the middle of the distribution of these metrics, meaning that this particular problem may be consistent across the whole dataset. It is therefore important to QC every scan, regardless of where its summary metrics lie on the distribution.  

In cases where every scan must be quality controlled, Mindcontrol's summary statistic distributions and annotation features can help prioritize which images to edit first. It may be more likely that images at the tail ends of their distributions require more time to quality control, or be more challenging and require an editor with more experience. When training new editors, Mindcontrol's annotation and notes features allow users to ask questions, mark questionable part of the image with the point or curve annotation feature, and assign images to more senior editors to review and give feedback. When multiple users are editing images using traditional, non-browser based tools, it is up to the user to save their edited images in a consistent manner, so that new users know which images have been edited, and where the original image came from. Inconsistent naming and folder structures could cause confusion to other lab members, edits could be lost in the filesystem once the original editor leaves, or even accidentally over-written. Using Mindcontrol can help avoid this problem, because edits are curated within the Mindcontrol database. Mindcontrol saves the voxel coordinates and the new value of the voxel, but does not apply edits to the actual image. Users can write scripts to apply the Mindcontrol painter coordinates to a volume, and write the output in a consistent naming structure. An example python script to do this can be found at \href{http://}{https://github.com/akeshavan/mindcontrol/wiki/Applying-Painter-Edits}.


%Mindcontrol is actively being used at UCSF to study imaging biomarkers of multiple sclerosis (MS) disease progression in a 12-year longitudinal cohort of over 500 patients. MRI plays a crucial role in the diagnosis of MS due to its sensitivity to the white matter lesions characteristic of this disease \cite{ge2006multiple}. Both the location and number of lesions are used in the diagnostic criteria of MS \cite{mcdonald2001recommended}; their evolution over time is considered a proxy for disease progression, and is closely monitored as a key outcome measure in clinical trials \cite{ge2000glatiramer}. Researchers have identified numerous imaging biomarkers of disease progression, including cortical atrophy \cite{fisher2008gray} and sensitive lesion quantification methods from FLAIR sequences \cite{Schmidt_2012}. 

%Currently, Mindcontrol is being used as a data management dashboard and plays a role in the semi-automated identification of multiple sclerosis lesions. The Lesion Segmentation Toolbox (LST) automates the detection of FLAIR hyper-intense lesions, which prevents user-bias of the lesion boundary \cite{Schmidt_2012}. However, because our acquisition protocols sufficiently differ from those of the LST developers, manual intervention by neuroradiologists is often necessary to correct false positives and false negatives in our dataset. Mindcontrol's point annotation feature is used by neuroradiologists to mark the center of a false positive lesion. The curve annotation feature is used to quickly note the rough outline of a false negative lesion. Custom Python scripts use these annotations to produce a corrected lesion segmentation map, which is then used to tune the parameters of the LST. This method avoids biasing the lesion boundary and saves time by allowing users to quickly mark lesions with one click instead of the traditional method of coloring the full lesion volume by hand. Distributions of the lesion count and lesion volume are used by the researchers to prioritize the cases requiring more intensive editing.

Mindcontrol is also being used at UCSF to coordinate a large-scale brain mask editing effort of $>$4000 exams in a cohort of multiple sclerosis patients. Using Mindcontrol's voxel editing or ``painting'' feature on a Microsoft Surface Pro 4 tablet with stylus, multiple research assistants are collaboratively erasing voxels incorrectly marked as brain and painting brain voxels that were not identified.  These edits are done with a stylus, which feels more natural and is faster than using a mouse. Researchers assign more complicated edits to the experts in the lab, write questions and comments in the ``notes'' section, and mark the brain as ``Edited'' once it is complete. A nightly cron-job applies their edits to the brain masks and assigns a reviewer to perform a final QC. All brains marked with a ``Pass'' will be added to a set of brain masks to be incorporated into a training set for the mincbeast brain extraction algorithm \cite{eskildsen2012beast}. Leveraging Mindcontrol as a semi-automated segmentation utility has made our processing methods more efficient, organized, and collaborative.